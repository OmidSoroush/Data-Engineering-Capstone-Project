{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "Twitter data posted about Amazon, Apple, Google, Microsoft, and Tesla, and market value data of these companies will be used to create a database that is optimized to query and analyze. An ETL pipeline is going to be built to create the database.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import psycopg2\n",
    "from sql_queries import fact_tweet_table_insert, user_table_insert, company_table_insert, value_table_insert, time_table_insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "A company's market values are affected by different factors. One of the important factors could be the public opinion about that company. This project ist going to analyze the correlation between the market value of company respect to the public opinion of that company. Particularly, this task will try to understand whether negative tweets about companie affect their market values.\n",
    "\n",
    "#### Describe and Gather Data\n",
    "\n",
    "##### Twitter Data\n",
    "This dataset as a part of the paper published in the 2020 IEEE International Conference on Big Data under the 6th Special Session on Intelligent Data Mining track. The dataset contains over 3 million unique tweets with their information such as tweet id, author of the tweet, post date, the text body of the tweet, and the number of comments, likes, and retweets of tweets matched with the related company.\n",
    "\n",
    "##### Company Value Data\n",
    "This dataset contains daily OPEN, CLOSE, VOLUME, HIGH, and LOW values of Amazon, Apple, Google, Microsoft, and Tesla companies as tagged by dates. Values are fetched from the official NASDAQ website.\n",
    "\n",
    "\n",
    "###### Twitter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "path = \"\"\n",
    "tweet = pd.read_csv(\"Tweet.csv\")\n",
    "pd.set_option('display.max_columns', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550441509175443456</td>\n",
       "      <td>VisualStockRSRC</td>\n",
       "      <td>1420070457</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550441672312512512</td>\n",
       "      <td>KeralaGuy77</td>\n",
       "      <td>1420070496</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550441732014223360</td>\n",
       "      <td>DozenStocks</td>\n",
       "      <td>1420070510</td>\n",
       "      <td>S&amp;P100 #Stocks Performance $HD $LOW $SBUX $TGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550442977802207232</td>\n",
       "      <td>ShowDreamCar</td>\n",
       "      <td>1420070807</td>\n",
       "      <td>$GM $TSLA: Volkswagen Pushes 2014 Record Recal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550443807834402816</td>\n",
       "      <td>i_Know_First</td>\n",
       "      <td>1420071005</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>550443808606126081</td>\n",
       "      <td>aaplstocknews</td>\n",
       "      <td>1420071005</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>550443809700851716</td>\n",
       "      <td>iknowfirst</td>\n",
       "      <td>1420071005</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>550443857142611968</td>\n",
       "      <td>Cprediction</td>\n",
       "      <td>1420071016</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>550443857595600896</td>\n",
       "      <td>iknowfirst_br</td>\n",
       "      <td>1420071017</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>550443857692078081</td>\n",
       "      <td>Gold_prediction</td>\n",
       "      <td>1420071017</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id           writer   post_date  \\\n",
       "0  550441509175443456  VisualStockRSRC  1420070457   \n",
       "1  550441672312512512      KeralaGuy77  1420070496   \n",
       "2  550441732014223360      DozenStocks  1420070510   \n",
       "3  550442977802207232     ShowDreamCar  1420070807   \n",
       "4  550443807834402816     i_Know_First  1420071005   \n",
       "5  550443808606126081    aaplstocknews  1420071005   \n",
       "6  550443809700851716       iknowfirst  1420071005   \n",
       "7  550443857142611968      Cprediction  1420071016   \n",
       "8  550443857595600896    iknowfirst_br  1420071017   \n",
       "9  550443857692078081  Gold_prediction  1420071017   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
       "1  Insanity of today weirdo massive selling. $aap...            0   \n",
       "2  S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
       "3  $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
       "4  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "5  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "6  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "7  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "8  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "9  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "\n",
       "   retweet_num  like_num  \n",
       "0            0         1  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         1  \n",
       "4            0         1  \n",
       "5            0         1  \n",
       "6            0         1  \n",
       "7            0         1  \n",
       "8            0         1  \n",
       "9            0         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Market price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = pd.read_json(\"CompanyValues.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>day_date</th>\n",
       "      <th>close_value</th>\n",
       "      <th>volume</th>\n",
       "      <th>open_value</th>\n",
       "      <th>high_value</th>\n",
       "      <th>low_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>317.94</td>\n",
       "      <td>38399530</td>\n",
       "      <td>319.25</td>\n",
       "      <td>321.150</td>\n",
       "      <td>316.4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>318.25</td>\n",
       "      <td>33449100</td>\n",
       "      <td>316.77</td>\n",
       "      <td>323.440</td>\n",
       "      <td>315.6300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>318.11</td>\n",
       "      <td>28236270</td>\n",
       "      <td>316.14</td>\n",
       "      <td>318.710</td>\n",
       "      <td>313.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>316.73</td>\n",
       "      <td>31380450</td>\n",
       "      <td>323.50</td>\n",
       "      <td>324.240</td>\n",
       "      <td>316.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>318.89</td>\n",
       "      <td>20450750</td>\n",
       "      <td>315.77</td>\n",
       "      <td>319.230</td>\n",
       "      <td>315.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>316.85</td>\n",
       "      <td>25672210</td>\n",
       "      <td>318.66</td>\n",
       "      <td>320.890</td>\n",
       "      <td>315.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>319.23</td>\n",
       "      <td>27876220</td>\n",
       "      <td>316.68</td>\n",
       "      <td>319.520</td>\n",
       "      <td>316.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>313.14</td>\n",
       "      <td>25432390</td>\n",
       "      <td>315.03</td>\n",
       "      <td>318.520</td>\n",
       "      <td>313.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>314.96</td>\n",
       "      <td>33843130</td>\n",
       "      <td>313.17</td>\n",
       "      <td>316.500</td>\n",
       "      <td>310.3241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>307.71</td>\n",
       "      <td>41587090</td>\n",
       "      <td>300.35</td>\n",
       "      <td>307.900</td>\n",
       "      <td>300.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-14</td>\n",
       "      <td>309.54</td>\n",
       "      <td>39732270</td>\n",
       "      <td>304.51</td>\n",
       "      <td>309.790</td>\n",
       "      <td>301.5300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>307.65</td>\n",
       "      <td>50155640</td>\n",
       "      <td>312.15</td>\n",
       "      <td>315.950</td>\n",
       "      <td>303.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>311.41</td>\n",
       "      <td>40575260</td>\n",
       "      <td>317.83</td>\n",
       "      <td>319.688</td>\n",
       "      <td>310.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>315.01</td>\n",
       "      <td>36486560</td>\n",
       "      <td>308.10</td>\n",
       "      <td>317.050</td>\n",
       "      <td>307.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>310.13</td>\n",
       "      <td>33511990</td>\n",
       "      <td>305.64</td>\n",
       "      <td>310.350</td>\n",
       "      <td>304.2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>303.74</td>\n",
       "      <td>28803760</td>\n",
       "      <td>303.22</td>\n",
       "      <td>305.170</td>\n",
       "      <td>301.9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>300.63</td>\n",
       "      <td>35583440</td>\n",
       "      <td>300.46</td>\n",
       "      <td>303.240</td>\n",
       "      <td>298.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>297.56</td>\n",
       "      <td>36937800</td>\n",
       "      <td>295.06</td>\n",
       "      <td>301.000</td>\n",
       "      <td>294.4600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>293.16</td>\n",
       "      <td>33391990</td>\n",
       "      <td>289.17</td>\n",
       "      <td>293.690</td>\n",
       "      <td>286.3172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>289.07</td>\n",
       "      <td>60154180</td>\n",
       "      <td>286.25</td>\n",
       "      <td>299.000</td>\n",
       "      <td>285.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-04-30</td>\n",
       "      <td>293.80</td>\n",
       "      <td>45765970</td>\n",
       "      <td>289.96</td>\n",
       "      <td>294.530</td>\n",
       "      <td>288.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>287.73</td>\n",
       "      <td>34320200</td>\n",
       "      <td>284.73</td>\n",
       "      <td>289.670</td>\n",
       "      <td>283.8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>278.58</td>\n",
       "      <td>28001190</td>\n",
       "      <td>285.08</td>\n",
       "      <td>285.830</td>\n",
       "      <td>278.2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker_symbol    day_date  close_value    volume  open_value  high_value  \\\n",
       "0           AAPL  2020-05-29       317.94  38399530      319.25     321.150   \n",
       "1           AAPL  2020-05-28       318.25  33449100      316.77     323.440   \n",
       "2           AAPL  2020-05-27       318.11  28236270      316.14     318.710   \n",
       "3           AAPL  2020-05-26       316.73  31380450      323.50     324.240   \n",
       "4           AAPL  2020-05-22       318.89  20450750      315.77     319.230   \n",
       "5           AAPL  2020-05-21       316.85  25672210      318.66     320.890   \n",
       "6           AAPL  2020-05-20       319.23  27876220      316.68     319.520   \n",
       "7           AAPL  2020-05-19       313.14  25432390      315.03     318.520   \n",
       "8           AAPL  2020-05-18       314.96  33843130      313.17     316.500   \n",
       "9           AAPL  2020-05-15       307.71  41587090      300.35     307.900   \n",
       "10          AAPL  2020-05-14       309.54  39732270      304.51     309.790   \n",
       "11          AAPL  2020-05-13       307.65  50155640      312.15     315.950   \n",
       "12          AAPL  2020-05-12       311.41  40575260      317.83     319.688   \n",
       "13          AAPL  2020-05-11       315.01  36486560      308.10     317.050   \n",
       "14          AAPL  2020-05-08       310.13  33511990      305.64     310.350   \n",
       "15          AAPL  2020-05-07       303.74  28803760      303.22     305.170   \n",
       "16          AAPL  2020-05-06       300.63  35583440      300.46     303.240   \n",
       "17          AAPL  2020-05-05       297.56  36937800      295.06     301.000   \n",
       "18          AAPL  2020-05-04       293.16  33391990      289.17     293.690   \n",
       "19          AAPL  2020-05-01       289.07  60154180      286.25     299.000   \n",
       "20          AAPL  2020-04-30       293.80  45765970      289.96     294.530   \n",
       "21          AAPL  2020-04-29       287.73  34320200      284.73     289.670   \n",
       "22          AAPL  2020-04-28       278.58  28001190      285.08     285.830   \n",
       "\n",
       "    low_value  \n",
       "0    316.4700  \n",
       "1    315.6300  \n",
       "2    313.0900  \n",
       "3    316.5000  \n",
       "4    315.3500  \n",
       "5    315.8700  \n",
       "6    316.2000  \n",
       "7    313.0100  \n",
       "8    310.3241  \n",
       "9    300.2100  \n",
       "10   301.5300  \n",
       "11   303.2100  \n",
       "12   310.9100  \n",
       "13   307.2400  \n",
       "14   304.2900  \n",
       "15   301.9700  \n",
       "16   298.8700  \n",
       "17   294.4600  \n",
       "18   286.3172  \n",
       "19   285.8500  \n",
       "20   288.3500  \n",
       "21   283.8900  \n",
       "22   278.2000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price.head(23)\n",
    "#len(price)\n",
    "#len(price.volume.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "\n",
    "first doing some EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Data\n",
      "Rows: tweet_id       3717964\n",
      "writer         3670691\n",
      "post_date      3717964\n",
      "body           3717964\n",
      "comment_num    3717964\n",
      "retweet_num    3717964\n",
      "like_num       3717964\n",
      "dtype: int64\n",
      "Columns: 7\n",
      "\n",
      "Market Price\n",
      "Rows: ticker_symbol    17528\n",
      "day_date         17528\n",
      "close_value      17528\n",
      "volume           17528\n",
      "open_value       17528\n",
      "high_value       17528\n",
      "low_value        17528\n",
      "dtype: int64\n",
      "Columns: 7\n"
     ]
    }
   ],
   "source": [
    "# EDA\n",
    "print(\"Twitter Data\")\n",
    "twitter_count=tweet.count()\n",
    "print(f\"Rows: {twitter_count}\")\n",
    "print(f\"Columns: {len(tweet.columns)}\")\n",
    "print()\n",
    "print(\"Market Price\")\n",
    "mrkt_price_count=price.count()\n",
    "print(f\"Rows: {mrkt_price_count}\")\n",
    "print(f\"Columns: {len(tweet.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data\n",
    "- convert the post_date column to date\n",
    "- check for missing values\n",
    "- check for duplicates values and drop them\n",
    "- add company symbol ticker to tweet data\n",
    "- create unique IDs for writer and symbol ticker columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the post_date column to date type\n",
    "def create_time_tbl(df, col):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: This function converts the numeric date column to datetime and create the time table.\n",
    "    Arguments:\n",
    "        df: dataframe. \n",
    "        col: the numeric column of the dataframe which need to be converted. \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    tweet['post_date'] = pd.to_datetime(df[col], unit='s')\n",
    "\n",
    "\n",
    "    time_data = []\n",
    "    for element in tweet['post_date']:\n",
    "        time_data.append([element, element.hour, element.day, element.week, element.month, element.year, element.day_name()])\n",
    "    column_labels = ('date_time', 'hour', 'day', 'week', 'month', 'year', 'weekday')\n",
    "    time_df = pd.DataFrame(time_data, columns=column_labels)\n",
    "    return time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 00:00:57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 00:01:36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 00:01:50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 00:06:47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 00:10:05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_time  hour  day  week  month  year   weekday\n",
       "0 2015-01-01 00:00:57     0    1     1      1  2015  Thursday\n",
       "1 2015-01-01 00:01:36     0    1     1      1  2015  Thursday\n",
       "2 2015-01-01 00:01:50     0    1     1      1  2015  Thursday\n",
       "3 2015-01-01 00:06:47     0    1     1      1  2015  Thursday\n",
       "4 2015-01-01 00:10:05     0    1     1      1  2015  Thursday"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the time table\n",
    "time_df = create_time_tbl(tweet, \"post_date\")\n",
    "time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_values(df):\n",
    "    \"\"\"\n",
    "    Description: This function checks for null values in a dataframe.\n",
    "    Arguments:\n",
    "        df: dataframe. \n",
    "    Returns:\n",
    "        columns with the number of null values\n",
    "    \"\"\"\n",
    "    # check for null values\n",
    "    nulls = df.isnull().sum().sort_values(ascending = False)\n",
    "    return nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "writer         47273\n",
       "tweet_id           0\n",
       "post_date          0\n",
       "body               0\n",
       "comment_num        0\n",
       "retweet_num        0\n",
       "like_num           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values in tweet data\n",
    "null_values(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"writer\" column is the only column with missing data. Since this column is not going to be used in the analysis, I am going to ignore the missings for this column for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker_symbol    0\n",
       "day_date         0\n",
       "close_value      0\n",
       "volume           0\n",
       "open_value       0\n",
       "high_value       0\n",
       "low_value        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values in the market price data\n",
    "null_values(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_repeated_records(df, col):\n",
    "    \"\"\"\n",
    "    Description: This function checks for duplicates values and drop them if any.\n",
    "    Arguments:\n",
    "        df: dataframe.\n",
    "        col: column of the dataframe\n",
    "    Returns:\n",
    "        number of duplicate records\n",
    "    \"\"\"\n",
    "    \n",
    "    # checking for duplicates values in the tweet data\n",
    "    dups = df[df[col].duplicated()]\n",
    "    if len(dups) > 0:\n",
    "        df.drop_duplicates(subset = [col], inplace = True)\n",
    "    return len(dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for duplicates values in the tweet data\n",
    "drop_repeated_records(tweet, \"tweet_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load the company data that contains company symbol, and merge this data with the tweet dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "618481"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_symbol = pd.read_csv('Company_Tweet.csv')\n",
    "# check for any duplicates in\n",
    "drop_repeated_records(company_symbol, \"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3717964, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge company symbol to the tweet data\n",
    "tweets = pd.merge(tweet,company_symbol,on='tweet_id',how='inner')\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter Data\n",
      "AAPL     1425013\n",
      "TSLA      958370\n",
      "AMZN      534008\n",
      "GOOG      312590\n",
      "MSFT      268257\n",
      "GOOGL     219726\n",
      "Name: ticker_symbol, dtype: int64\n",
      "\n",
      "Market Price Data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GOOGL    3085\n",
       "AMZN     3085\n",
       "AAPL     3085\n",
       "MSFT     3085\n",
       "TSLA     3065\n",
       "GOOG     2123\n",
       "Name: ticker_symbol, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count unique values of ticker symbol \n",
    "print(\"Twitter Data\")\n",
    "print(tweets.ticker_symbol.value_counts())\n",
    "print()\n",
    "print(\"Market Price Data\")\n",
    "price.ticker_symbol.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create unique IDs for writer and symbol ticker column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>writer</th>\n",
       "      <th>post_date</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>retweet_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>writer_id</th>\n",
       "      <th>ticker_symbol_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>550441509175443456</td>\n",
       "      <td>VisualStockRSRC</td>\n",
       "      <td>2015-01-01 00:00:57</td>\n",
       "      <td>lx21 made $10,008  on $AAPL -Check it out! htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>9577843435</td>\n",
       "      <td>9577843435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550441672312512512</td>\n",
       "      <td>KeralaGuy77</td>\n",
       "      <td>2015-01-01 00:01:36</td>\n",
       "      <td>Insanity of today weirdo massive selling. $aap...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>5005303368</td>\n",
       "      <td>9577843435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>550441732014223360</td>\n",
       "      <td>DozenStocks</td>\n",
       "      <td>2015-01-01 00:01:50</td>\n",
       "      <td>S&amp;P100 #Stocks Performance $HD $LOW $SBUX $TGT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2703301249</td>\n",
       "      <td>5005303368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>550442977802207232</td>\n",
       "      <td>ShowDreamCar</td>\n",
       "      <td>2015-01-01 00:06:47</td>\n",
       "      <td>$GM $TSLA: Volkswagen Pushes 2014 Record Recal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>2666063943</td>\n",
       "      <td>2703301249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550443807834402816</td>\n",
       "      <td>i_Know_First</td>\n",
       "      <td>2015-01-01 00:10:05</td>\n",
       "      <td>Swing Trading: Up To 8.91% Return In 14 Days h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>8171504636</td>\n",
       "      <td>9577843435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id           writer           post_date  \\\n",
       "0  550441509175443456  VisualStockRSRC 2015-01-01 00:00:57   \n",
       "1  550441672312512512      KeralaGuy77 2015-01-01 00:01:36   \n",
       "2  550441732014223360      DozenStocks 2015-01-01 00:01:50   \n",
       "3  550442977802207232     ShowDreamCar 2015-01-01 00:06:47   \n",
       "4  550443807834402816     i_Know_First 2015-01-01 00:10:05   \n",
       "\n",
       "                                                body  comment_num  \\\n",
       "0  lx21 made $10,008  on $AAPL -Check it out! htt...            0   \n",
       "1  Insanity of today weirdo massive selling. $aap...            0   \n",
       "2  S&P100 #Stocks Performance $HD $LOW $SBUX $TGT...            0   \n",
       "3  $GM $TSLA: Volkswagen Pushes 2014 Record Recal...            0   \n",
       "4  Swing Trading: Up To 8.91% Return In 14 Days h...            0   \n",
       "\n",
       "   retweet_num  like_num ticker_symbol   writer_id  ticker_symbol_id  \n",
       "0            0         1          AAPL  9577843435        9577843435  \n",
       "1            0         0          AAPL  5005303368        9577843435  \n",
       "2            0         0          AMZN  2703301249        5005303368  \n",
       "3            0         1          TSLA  2666063943        2703301249  \n",
       "4            0         1          AAPL  8171504636        9577843435  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create ids for writer column\n",
    "np.random.seed(1)\n",
    "names = tweets['writer'].unique().tolist()\n",
    "ids = np.random.randint(low=1e9, high=1e10, size = len(names))\n",
    "len(set(ids))\n",
    "maps = {k:v for k,v in zip(names, ids)}\n",
    "tweets['writer_id'] = tweets['writer'].map(maps)\n",
    "\n",
    "# create ids for ticker_symbol column\n",
    "np.random.seed(1)\n",
    "symbol = tweets['ticker_symbol'].unique().tolist()\n",
    "sym_id = np.random.randint(low=1e9, high=1e10, size = len(symbol))\n",
    "len(set(sym_id))\n",
    "mappings = {k:v for k,v in zip(symbol, sym_id)}\n",
    "tweets['ticker_symbol_id'] = tweets['ticker_symbol'].map(mappings)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### giving the same ticker symbol ID to the ticker symbol in price dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker_symbol\n",
       "AAPL     [9577843435]\n",
       "AMZN     [5005303368]\n",
       "GOOG     [2666063943]\n",
       "GOOGL    [7590257550]\n",
       "MSFT     [8171504636]\n",
       "TSLA     [2703301249]\n",
       "Name: ticker_symbol_id, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create ids for ticker_symbol column in price dataset\n",
    "mappings = {k:v for k,v in zip(tweets[\"ticker_symbol\"].unique(), tweets[\"ticker_symbol_id\"].unique())}\n",
    "price['ticker_symbol_id'] = price['ticker_symbol'].map(mappings)\n",
    "price.groupby(\"ticker_symbol\")[\"ticker_symbol_id\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "A star schema design is chosen for the database. This schema has one Fact Table having twitter data, and four supporting Dimension Tables. A star schema Database design allows for flexible queries by separating dimensions into specific tables in a clean way. Moreover, star schema makes it easy to create OLAP cubes efficiently.\n",
    "\n",
    "##### Fact table\n",
    "\n",
    "contains twitter data:\n",
    "\n",
    "- tweet_id int PRIMARY KEY\n",
    "- date_time TIMESTAMP\n",
    "- writer_id bigint\n",
    "- ticker_symbol_id bigint\n",
    "- body text NOT NULL\n",
    "- comment_num int\n",
    "- retweet_num int\n",
    "- like_num int\n",
    "\n",
    "\n",
    "##### User Dimension Table\n",
    "\n",
    "- writer_id bigint PRIMARY KEY\n",
    "- writer text\n",
    "\n",
    "##### Company Dimension Table\n",
    "\n",
    "- ticker_symbol_id bigint PRIMARY KEY\n",
    "- ticker_symbol text\n",
    "\n",
    "##### Value Dimension Table\n",
    "\n",
    "- day_date TIMESTAMP PRIMARY KEY\n",
    "- volume int\n",
    "- open_value float\n",
    "- high_value float\n",
    "- low_value float\n",
    "- ticker_symbol_id bigint\n",
    "\n",
    "##### Time Dimension Table\n",
    "\n",
    "- date_time TIMESTAMP PRIMARY KEY\n",
    "- hour int, day int\n",
    "- week int\n",
    "- month int\n",
    "- year int\n",
    "- weekday text\n",
    "\n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "##### Pipelinesteps\n",
    "\n",
    "   * Preprocess and cleanup the data as explained in step 2\n",
    "   * Join the tweet data with the company symbol data \n",
    "   * Create the time table from the post_date column of the tweet data\n",
    "   * Create tables by running the create_table.py\n",
    "   * Insert the Data into the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After running create_tables.py, insert the data into the database\n",
    "conn = psycopg2.connect(\"dbname=capstone user=postgres password=password\")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet_data(cur, df):\n",
    "    \"\"\"\n",
    "    Description: This function inserts data from tweets dataframe to three tables (tweets, users and company) in PostgreSQL database.\n",
    "    Arguments:\n",
    "        cur: the cursor object. \n",
    "        df: the dataframe. \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # insert tweet record\n",
    "    df_tweet = tweets[[\"tweet_id\", \"post_date\", \"writer_id\", \"ticker_symbol_id\", \"body\", \"comment_num\", \"retweet_num\", \"like_num\"]]\n",
    "\n",
    "    for index, row in df_tweet.iterrows():\n",
    "        cur.execute(fact_tweet_table_insert, list(row.values))\n",
    "        conn.commit()\n",
    "    \n",
    "    # insert user record\n",
    "    df_user = tweets[[\"writer_id\", \"writer\"]]\n",
    "\n",
    "    for index, row in df_user.iterrows():\n",
    "        cur.execute(user_table_insert, list(row.values))\n",
    "        conn.commit()\n",
    "    \n",
    "    # insert company symbol data\n",
    "    df_company = tweets[[\"ticker_symbol_id\", \"ticker_symbol\"]]\n",
    "    df_company = df_company.drop_duplicates(subset = [\"ticker_symbol_id\"])\n",
    "\n",
    "    for index, row in df_company.iterrows():\n",
    "        cur.execute(company_table_insert, list(row.values))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_time_data(cur, df):\n",
    "    \"\"\"\n",
    "    Description: This function saves the data from tweet dataframe into one table (time) in PostgreSQL database.\n",
    "    Arguments:\n",
    "        cur: the cursor object. \n",
    "        df: the dataframe. \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # expand time data to lower units like day, hour etc.\n",
    "    time_data = []\n",
    "    for element in tweet['post_date']:\n",
    "        time_data.append([element, element.hour, element.day, element.week, element.month, element.year, element.day_name()])\n",
    "    column_labels = ('date_time', 'hour', 'day', 'week', 'month', 'year', 'weekday')\n",
    "    time_df = pd.DataFrame(time_data, columns=column_labels)\n",
    "\n",
    "    # insert time data\n",
    "    df_time = time_df[[\"date_time\", \"hour\", \"day\", \"week\", \"month\", \"year\", \"weekday\"]]\n",
    "\n",
    "    for index, row in df_time.iterrows():\n",
    "        cur.execute(time_table_insert, list(row.values))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_value_data(cur, df):\n",
    "    \"\"\"\n",
    "    Description: This function saves data from price table into one table (value) in PostgreSQL database.\n",
    "    Arguments:\n",
    "        cur: the cursor object. \n",
    "        df: dataframe. \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # get values for the value table\n",
    "    df_value = price[[\"day_date\", \"volume\", \"open_value\", \"high_value\", \"low_value\", \"ticker_symbol_id\"]]\n",
    "\n",
    "    # insert data into the value table\n",
    "    for index, row in df_value.iterrows():\n",
    "        cur.execute(value_table_insert, list(row.values))\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert the tweet data\n",
    "process_tweet_data(cur, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the time data\n",
    "process_time_data(cur, tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert value data\n",
    "process_value_data(cur, price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "1- The function below checks whether there exist data in each table that we created. If there is no data found in      any table, the data quality check fails. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_check(table, description):\n",
    "    '''\n",
    "    Input: Postgres table, description of the table\n",
    "    Output: Print out the number of rows in the table or it fails\n",
    "    '''\n",
    "    \n",
    "    cur.execute(f\"SELECT * FROM {table}\")\n",
    "    rows = cur.fetchall()\n",
    "    result = len(rows)\n",
    "    if result > 0:\n",
    "        print(\"Data quality check successful for {} with {} records\".format(description, result))\n",
    "    else:\n",
    "        print(\"Data quality check failed for {} with zero records\".format(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check successful for tweets table with 3717964 records\n",
      "Data quality check successful for user table with 140131 records\n",
      "Data quality check successful for company table with 6 records\n",
      "Data quality check successful for value table with 17528 records\n",
      "Data quality check successful for time table with 3421363 records\n"
     ]
    }
   ],
   "source": [
    "quality_check(\"tweets\", \"tweets table\")\n",
    "quality_check(\"users\", \"user table\")\n",
    "quality_check(\"company\", \"company table\")\n",
    "quality_check(\"value\", \"value table\")\n",
    "quality_check(\"time\", \"time table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Function below checks whether a column has a type as expected. It returns true if the column type satisfies expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_check(table, col, type_col):\n",
    "    '''\n",
    "    Input: Postgres table, table column, type of the column\n",
    "    Output: Print True if the column has the expected type\n",
    "    '''\n",
    "    \n",
    "    cur.execute(f\"SELECT {col} FROM {table} limit 20\")\n",
    "    tuples = cur.fetchone()\n",
    "    result = isinstance(tuples[0], type_col)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "type_check(\"tweets\", \"writer_id\", int)\n",
    "type_check(\"tweets\", \"body\", str)\n",
    "type_check(\"value\", \"high_value\", float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "##### Fact table\n",
    "\n",
    "contains twitter data:\n",
    "\n",
    "- tweet_id int ID number for each tweet\n",
    "- date_time TIMESTAMP date and time of the tweet (foreign key)\n",
    "- writer_id bigint a uniqe ID for each person who posted the tweet (foreign key)\n",
    "- ticker_symbol_id bigint a unique ID for every company (foreign key)\n",
    "- body text NOT NULL text of the tweet posted\n",
    "- comment_num int number of comments the tweet received\n",
    "- retweet_num int number of retweets the tweet received\n",
    "- like_num int number of likes the tweet received\n",
    "\n",
    "\n",
    "##### User Dimension Table\n",
    "\n",
    "can be joined to the fact table by the writer_id \n",
    "\n",
    "- writer_id bigint PRIMARY KEY unique ID for each writer of the tweet\n",
    "- writer text screen name for the writer of the tweet\n",
    "\n",
    "##### Company Dimension Table\n",
    "\n",
    "can be joined to the fact table by the ticker_symbol_id\n",
    "\n",
    "- ticker_symbol_id bigint PRIMARY KEY unique ID for the company\n",
    "- ticker_symbol text symbol of the countries included in the analysis\n",
    "\n",
    "##### Value Dimension Table\n",
    "\n",
    "\n",
    "can be joined to the fact table by the day_date\n",
    "\n",
    "- day_date TIMESTAMP PRIMARY KEY date and time of each value record\n",
    "- volume int \n",
    "- open_value float open value\n",
    "- high_value float the highest value of a share of stocks of the company within 24 hours\n",
    "- low_value float the lowest value of a share of stocks of the company within 24 hours\n",
    "- ticker_symbol_id bigint unique ID for each company\n",
    "\n",
    "##### Time Dimension Table\n",
    "\n",
    "can be joined to the fact table by the date_time\n",
    "\n",
    "- date_time TIMESTAMP PRIMARY KEY date and time in which the tweet was posted\n",
    "- hour int, day int\n",
    "- week int\n",
    "- month int\n",
    "- year int\n",
    "- weekday text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    " \n",
    "## Choice of tools and technologies\n",
    "\n",
    "Pandas is used to preprocess and clean up the data. It is a very efficient tool for this purpose. I have used Python to realize this project because Python is the language I am comfortable with, and it is one of the most used languages for these purposes.\n",
    "Since the data will be analyzed on a monthly basis, a monthly update of the data is recommended. \n",
    "\n",
    "## What if?\n",
    "1. The data was increased by 100x.\n",
    "\n",
    "    * Spark can be used to process the data in an efficient and distributed way. Amazon Redshift is also helpful in such a scenario since         it is an optimized analytical database tool for such heavy work-loads.\n",
    "    \n",
    "2. The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "\n",
    "    * Airflow can be used in this scenario. In case of failures, use Dag retries and send failure emails.\n",
    "\n",
    "3. The database needed to be accessed by 100+ people.\n",
    "    * Redshift is the right tool in this case because it has auto-scaling capabilities and high read performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
